{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1: Sentence Transformer Implementation**"
      ],
      "metadata": {
        "id": "DTT9nBCxXSz1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmuogQKHXLVo",
        "outputId": "373ce10d-f1b7-4523-90c1-469087a59f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 768])\n",
            "\n",
            "\n",
            "\n",
            "tensor([[-0.7400, -0.6163, -0.9663,  ..., -0.9046, -0.7043,  0.7008],\n",
            "        [-0.9473, -0.6311, -0.9113,  ..., -0.8447, -0.6211,  0.9265],\n",
            "        [-0.8555, -0.4487, -0.8454,  ..., -0.6958, -0.6657,  0.9032],\n",
            "        [-0.8796, -0.5841, -0.8118,  ..., -0.5250, -0.6784,  0.9095]])\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Loading pre trained BERT model and tokenizer\n",
        "tokenizer_var = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model_var = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Sample sentences for performing our task\n",
        "sentences_list = [\"Cricket is an amazing sport.\", \"Indian cricket team is a champion.\", \"Virat Kohli is my favorite player.\",\"Dhoni is a superstar.\"]\n",
        "\n",
        "# Tokenize and encode all the sentences\n",
        "inputs_var = tokenizer_var(sentences_list, padding = True, truncation = True, return_tensors = \"pt\")\n",
        "\n",
        "# Get sentence embeddings\n",
        "with torch.no_grad():\n",
        "    outputs_var = model_var(**inputs_var)\n",
        "    sentence_embeddings = outputs_var.pooler_output\n",
        "\n",
        "# Printing outputs/results\n",
        "print(sentence_embeddings.shape)\n",
        "print(\"\\n\\n\")\n",
        "print(sentence_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regarding the model architecture, I didn't have to make any choices since I used the pre-trained BERT model as it is. The BERT model is a transformer-based model that has been pre-trained on a large corpus of text data, and it can be fine-tuned or used as a feature extractor for various natural language processing tasks, including sentence embedding.**"
      ],
      "metadata": {
        "id": "9-lyX9iqZtsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2: Multi-Task Learning Expansion**"
      ],
      "metadata": {
        "id": "EZFRl9LjZy1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Loading pre trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define the multi tasking BERT model\n",
        "class MultiTaskBertModel(nn.Module):\n",
        "    def __init__(self, bert_model, num_classes_task_a, num_classes_task_b):\n",
        "        super(MultiTaskBertModel, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.task_a_head = nn.Linear(bert_model.config.hidden_size, num_classes_task_a)\n",
        "        self.task_b_head = nn.Linear(bert_model.config.hidden_size, num_classes_task_b)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        bert_output = self.bert(input_ids, attention_mask, token_type_ids)\n",
        "        task_a_output = self.task_a_head(bert_output.pooler_output)\n",
        "        task_b_output = self.task_b_head(bert_output.last_hidden_state)\n",
        "        return task_a_output, task_b_output\n",
        "\n",
        "# Instantiate the multitask models\n",
        "num_classes_task_a = 5  # For Sentence Classification\n",
        "num_classes_task_b = 10  # For Named Entity Recognition\n",
        "model = MultiTaskBertModel(bert_model, num_classes_task_a, num_classes_task_b)\n",
        "\n",
        "# Sample sentences for performing our task\n",
        "sentences_list = [\"Cricket is an amazing sport.\", \"Indian cricket team is a champion.\", \"Virat Kohli is my favorite player.\", \"Dhoni is a superstar.\"]\n",
        "\n",
        "# Tokenize and encode all the sentences\n",
        "inputs = tokenizer(sentences_list, padding = True, truncation = True, return_tensors = \"pt\")\n",
        "\n",
        "# Get multitask outputs\n",
        "task_a_output, task_b_output = model(**inputs)\n",
        "\n",
        "# Define loss functions for each task\n",
        "task_a_loss_fn = nn.CrossEntropyLoss()\n",
        "task_b_loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Compute losses for each task\n",
        "task_a_labels = torch.tensor([0, 1, 2, 3])\n",
        "\n",
        "# Create target labels for Task B with the same shape as the models output\n",
        "task_b_labels = torch.zeros_like(task_b_output, dtype = torch.float32)\n",
        "task_b_labels[:, 0, 0] = 1\n",
        "task_b_labels[:, 1, 1] = 1\n",
        "\n",
        "task_a_loss = task_a_loss_fn(task_a_output, task_a_labels)\n",
        "task_b_loss = task_b_loss_fn(task_b_output.view(-1, num_classes_task_b), task_b_labels.view(-1, num_classes_task_b))\n",
        "\n",
        "# Combine losses for multitask learning with equal weightage\n",
        "task_a_weight = 0.5\n",
        "task_b_weight = 0.5\n",
        "combined_loss = task_a_loss * task_a_weight + task_b_loss * task_b_weight\n",
        "\n",
        "# Optimize the combined loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "combined_loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "# Print the multitask outputs\n",
        "print(\"Task A Output (Sentence Classification):\")\n",
        "print(task_a_output)\n",
        "print(\"\\nTask B Output (Named Entity Recognition):\")\n",
        "print(task_b_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGlWXAYA7eKl",
        "outputId": "c12ae5c4-f0d3-486e-8159-8fd52e815b73"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task A Output (Sentence Classification):\n",
            "tensor([[-0.1995,  0.4531,  0.0522,  0.0714, -0.0694],\n",
            "        [-0.2850,  0.3624,  0.0745,  0.1833,  0.1519],\n",
            "        [-0.2626,  0.3303, -0.0718,  0.1448,  0.1404],\n",
            "        [-0.2447,  0.3235, -0.0451,  0.2304,  0.1812]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Task B Output (Named Entity Recognition):\n",
            "tensor([[[-0.0782,  0.2481,  0.2469, -0.2666,  0.0767,  0.0966, -0.2244,\n",
            "           0.1793, -0.3685, -0.1526],\n",
            "         [ 0.2004, -0.0919, -0.4463,  0.1196,  0.2945,  0.2364, -0.1911,\n",
            "           0.2368, -0.0732,  0.2632],\n",
            "         [ 0.2033, -0.1546,  0.1038, -0.0460,  0.2551,  0.2414, -0.0045,\n",
            "          -0.1665, -0.0410,  0.0941],\n",
            "         [-0.1745, -0.2476,  0.1787, -0.2564,  0.3351,  0.2298, -0.0077,\n",
            "          -0.0946, -0.1218,  0.1827],\n",
            "         [ 0.1389, -0.2824, -0.0690, -0.0648,  0.0958,  0.2538,  0.0642,\n",
            "           0.4035, -0.0128,  0.5688],\n",
            "         [ 0.2461, -0.3082, -0.1450,  0.1179,  0.4300,  0.4292,  0.3234,\n",
            "          -0.1333, -0.3076,  0.3924],\n",
            "         [ 0.1265,  0.3092,  0.2496,  0.0859, -0.1344, -0.1314,  0.0077,\n",
            "           0.1592,  0.1420,  0.1707],\n",
            "         [ 0.1612,  0.2716,  0.3619,  0.0714, -0.0243, -0.2288,  0.0371,\n",
            "           0.0655, -0.1300,  0.1618],\n",
            "         [-0.2779,  0.0959, -0.1755,  0.0568,  0.2247,  0.0348, -0.2708,\n",
            "           0.1621, -0.1301,  0.0025],\n",
            "         [-0.1878,  0.1307, -0.2946,  0.1260,  0.1127,  0.1332, -0.3239,\n",
            "           0.2604,  0.1105,  0.0923],\n",
            "         [-0.2476,  0.0731, -0.1957,  0.0632,  0.1827,  0.0629, -0.2567,\n",
            "           0.1712, -0.1140,  0.0305]],\n",
            "\n",
            "        [[-0.0988, -0.1354,  0.1088, -0.3954,  0.1673,  0.1741, -0.2120,\n",
            "           0.2368, -0.1161, -0.0282],\n",
            "         [-0.0670, -0.3204, -0.4661, -0.3158,  0.3888,  0.2817,  0.2007,\n",
            "           0.5209,  0.1472,  0.4180],\n",
            "         [ 0.3460, -0.3994, -0.1440, -0.2336,  0.2997,  0.0020, -0.0625,\n",
            "          -0.2358, -0.2151,  0.2699],\n",
            "         [ 0.0509, -0.2742, -0.6016,  0.0652,  0.5991,  0.0962,  0.2667,\n",
            "           0.4172, -0.2496,  0.3305],\n",
            "         [-0.0151, -0.1070, -0.1820,  0.1870,  0.4742,  0.1420,  0.1193,\n",
            "           0.2095, -0.2890,  0.3671],\n",
            "         [-0.3253, -0.1641, -0.1288,  0.0133,  0.2375, -0.0463, -0.0404,\n",
            "           0.2872,  0.0822,  0.5274],\n",
            "         [ 0.4001, -0.2726, -0.1782, -0.0552,  0.1573,  0.4599, -0.0735,\n",
            "           0.3160, -0.1494,  0.7940],\n",
            "         [ 0.0690,  0.0871, -0.6146, -0.1583,  0.4653,  0.0851, -0.1584,\n",
            "           0.3144,  0.2285,  0.3429],\n",
            "         [ 0.0778,  0.1268,  0.3730,  0.0706,  0.0967, -0.4621,  0.2235,\n",
            "           0.2508, -0.4284,  0.4431],\n",
            "         [-0.0951, -0.0628, -0.2181,  0.0221,  0.2284,  0.0578, -0.1222,\n",
            "           0.2402,  0.0232,  0.2797],\n",
            "         [ 0.0597,  0.0243, -0.3747, -0.1706,  0.2086,  0.1299, -0.1255,\n",
            "           0.2165,  0.2321,  0.2884]],\n",
            "\n",
            "        [[-0.1677,  0.1383,  0.2781, -0.3495,  0.0670,  0.1953, -0.2074,\n",
            "           0.3807, -0.1598, -0.2974],\n",
            "         [-0.7299, -0.0597, -0.2738, -0.3670,  0.3142,  0.4976, -0.2168,\n",
            "           0.0964,  0.0368,  0.3060],\n",
            "         [-0.6637, -0.4050, -0.3783, -0.3934,  0.4667,  0.0172,  0.1034,\n",
            "           0.0151, -0.0955,  0.4252],\n",
            "         [-0.3084, -0.5951,  0.1055, -0.1501, -0.1295,  0.6764, -0.0811,\n",
            "          -0.5724, -0.1141,  0.3918],\n",
            "         [-0.1647, -0.2210, -0.3878, -0.2861,  0.7079,  0.1993, -0.3208,\n",
            "           0.2181,  0.3476, -0.0749],\n",
            "         [ 0.1315, -0.1510,  0.1933,  0.0123,  0.3633,  0.3585, -0.1049,\n",
            "           0.3317,  0.0917, -0.4318],\n",
            "         [ 0.3746, -0.3424, -0.3604, -0.1406,  0.6663,  0.5002, -0.3269,\n",
            "           0.5787, -0.2117,  0.2903],\n",
            "         [ 0.4769, -0.0940, -0.1557,  0.0954,  0.3428,  0.3747,  0.1130,\n",
            "           0.3294,  0.1919,  0.0664],\n",
            "         [ 0.1094,  0.2226, -0.1065,  0.0765,  0.3709,  0.5432, -0.2856,\n",
            "           0.0976, -0.2429,  0.4466],\n",
            "         [ 0.0061,  0.1539,  0.3984,  0.0843, -0.1449, -0.2197,  0.1362,\n",
            "           0.0640,  0.1476,  0.2838],\n",
            "         [ 0.0348,  0.1578,  0.5294,  0.1141, -0.0911, -0.3024,  0.1647,\n",
            "          -0.0230, -0.0570,  0.2462]],\n",
            "\n",
            "        [[-0.0117,  0.1169,  0.2490, -0.3428, -0.1289,  0.0392, -0.2384,\n",
            "           0.2977,  0.0654, -0.0594],\n",
            "         [-0.0067, -0.1460, -0.3491, -0.4553,  0.2130,  0.6820, -0.1089,\n",
            "          -0.1240,  0.5780,  0.6416],\n",
            "         [-0.1895, -0.1748, -0.4310, -0.4054,  0.2484,  0.6871, -0.0187,\n",
            "           0.1965,  0.2888,  0.7901],\n",
            "         [ 0.2899, -0.3151,  0.0878, -0.0456,  0.1841,  0.1918,  0.0025,\n",
            "           0.1972, -0.0662,  0.1058],\n",
            "         [ 0.0375, -0.1725,  0.0116, -0.0299, -0.0639,  0.0349, -0.0217,\n",
            "           0.3053,  0.5556,  0.3655],\n",
            "         [ 0.6917,  0.0111, -0.4007, -0.3382, -0.0967,  0.4692, -0.4038,\n",
            "           0.1998,  0.2421,  0.7071],\n",
            "         [ 0.2236,  0.2725, -0.6056, -0.0825,  0.2440,  0.0314, -0.2498,\n",
            "           0.3789,  0.1877,  0.2890],\n",
            "         [ 0.3135,  0.1816,  0.4023,  0.1165, -0.0365, -0.1715,  0.0312,\n",
            "           0.1042, -0.1741,  0.3864],\n",
            "         [ 0.0746,  0.0159, -0.2659, -0.0138,  0.0357,  0.1473, -0.2553,\n",
            "           0.1601,  0.0728,  0.2426],\n",
            "         [ 0.1158,  0.0866, -0.2969, -0.0965, -0.0961,  0.0894, -0.1085,\n",
            "           0.0852,  0.2417,  0.1861],\n",
            "         [ 0.0370,  0.0624, -0.2800, -0.0583,  0.0040,  0.1558, -0.1487,\n",
            "           0.1043,  0.1233,  0.2365]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The main change in the architecture is the addition of task specific output heads on top of the pre-trained BERT model. We created a new class called MultiTaskBertModel which inherits from nn.Module. This class takes the BERT model and adds two separate heads: task_a_head for Sentence Classification and task_b_head for Named Entity Recognition.**\n",
        "\n",
        "\n",
        "\n",
        "**These heads are linear layers that take the relevant output from BERT (pooler output for Task A and last hidden state for Task B) and map it to the respective number of classes for each task. In the forward method, we pass the input through BERT and then through these task-specific heads to get the final output for each task.**\n",
        "\n",
        "\n",
        "\n",
        "**For training, we compute the loss for each task separately using appropriate loss functions (CrossEntropyLoss for Task A and BCEWithLogitsLoss for Task B). To handle the shape mismatch between target labels and model output for Task B, we create a tensor task_b_labels with the same shape as the model's output and fill it with the correct labels for each token.**\n",
        "\n",
        "\n",
        "\n",
        "**We then combine the losses for both tasks using a weighted sum and optimize this combined loss using an optimizer like Adam. By making these architectural changes and adjustments to the training process, we can leverage BERT for multi-task learning, allowing the model to learn and generalize across multiple NLP tasks simultaneously.**"
      ],
      "metadata": {
        "id": "9bg48EcR8l5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3: Training Considerations**\n",
        "\n",
        "**Question:** Discuss the implications and advantages of each scenario and explain your rationale as to how the model should be trained given the following:\n",
        "If the entire network should be frozen.\n",
        "If only the transformer backbone should be frozen.\n",
        "If only one of the task-specific heads (either for Task A or Task B) should be frozen.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "The decision to freeze or not freeze different parts of the multi-task model during training has significant implications on the model's performance and learning capabilities.\n",
        "\n",
        "If the entire network, including the pre-trained BERT model and the task-specific heads, is frozen, the model will not be able to learn or update any of its parameters during training, limiting its performance to the initial capabilities of the pre-trained BERT model.\n",
        "\n",
        "Freezing only the transformer backbone (the pre-trained BERT model) while allowing the task-specific heads to be trainable is a common approach in multi-task learning, as it allows the model to leverage the pre-trained knowledge from BERT while fine-tuning the task-specific heads to learn the nuances of each task.\n",
        "\n",
        "On the other hand, if one of the task-specific heads (either for Task A or Task B) is frozen while allowing the other head and the transformer backbone to be trainable, the model will be able to learn and adapt for one task but not the other, which can be useful in scenarios where one task is more important or requires more fine-tuning than the other, but may lead to suboptimal performance for the task with the frozen head."
      ],
      "metadata": {
        "id": "8TNtXnZt-Sf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Consider a scenario where transfer learning can be beneficial. Explain how you would approach the transfer learning process, including:\n",
        "The choice of a pre-trained model.\n",
        "The layers you would freeze/unfreeze.\n",
        "The rationale behind these choices.\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Consider a scenario where we have a small dataset for a text classification task, like identifying positive or negative reviews for a product. In such cases, transfer learning can be very helpful as it allows us to leverage the knowledge learned from a large pre-trained language model trained on a massive amount of text data. For this task, I would choose a pre-trained model like BERT, as these models have learned rich representations of language that can be effectively transferred to our specific task.\n",
        "\n",
        "When fine-tuning these pre-trained models, it is common to freeze the weights of the lower layers (like the embedding layer and initial transformer layers) and only fine-tune the higher layers (like the final few transformer layers and the classification head). The lower layers have learned general language representations that are useful for various tasks, so freezing them preserves this valuable knowledge. The higher layers, on the other hand, are more task-specific and need to be fine-tuned to adapt the model to our specific text classification task and dataset. This approach strikes a balance between leveraging the pre-trained knowledge from the lower layers and allowing the model to specialize for our target task through fine-tuning the higher layers."
      ],
      "metadata": {
        "id": "erokDOtV_J8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 4: Layer-wise Learning Rate Implementation (BONUS)**"
      ],
      "metadata": {
        "id": "dMU42mhbBAJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Loading pre trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define the multitask BERT model\n",
        "class MultiTaskBertModel(nn.Module):\n",
        "    def __init__(self, bert_model, num_classes_task_a, num_classes_task_b):\n",
        "        super(MultiTaskBertModel, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.task_a_head = nn.Linear(bert_model.config.hidden_size, num_classes_task_a)\n",
        "        self.task_b_head = nn.Linear(bert_model.config.hidden_size, num_classes_task_b)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        bert_output = self.bert(input_ids, attention_mask, token_type_ids)\n",
        "        task_a_output = self.task_a_head(bert_output.pooler_output)\n",
        "        task_b_output = self.task_b_head(bert_output.last_hidden_state)\n",
        "        return task_a_output, task_b_output\n",
        "\n",
        "# Instantiate the multitask model\n",
        "num_classes_task_a = 5  # For Sentence Classification\n",
        "num_classes_task_b = 10  # For Named Entity Recognition\n",
        "model = MultiTaskBertModel(bert_model, num_classes_task_a, num_classes_task_b)\n",
        "\n",
        "# Sample sentences for performing our task\n",
        "sentences_list = [\"Cricket is an amazing sport.\", \"Indian cricket team is a champion.\", \"Virat Kohli is my favorite player.\", \"Dhoni is a superstar.\"]\n",
        "\n",
        "# Tokenize and encode all the sentences\n",
        "inputs = tokenizer(sentences_list, padding = True, truncation = True, return_tensors = \"pt\")\n",
        "\n",
        "# Get multi-task outputs\n",
        "task_a_output, task_b_output = model(**inputs)\n",
        "\n",
        "# Define loss functions for each task\n",
        "task_a_loss_fn = nn.CrossEntropyLoss()\n",
        "task_b_loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Compute losses for each task\n",
        "task_a_labels = torch.tensor([0, 1, 2, 3])\n",
        "\n",
        "# Create target labels for Task B with the same shape as the models output\n",
        "task_b_labels = torch.zeros_like(task_b_output, dtype = torch.float32)\n",
        "task_b_labels[:, 0, 0] = 1\n",
        "task_b_labels[:, 1, 1] = 1\n",
        "\n",
        "task_a_loss = task_a_loss_fn(task_a_output, task_a_labels)\n",
        "task_b_loss = task_b_loss_fn(task_b_output.view(-1, num_classes_task_b), task_b_labels.view(-1, num_classes_task_b))\n",
        "\n",
        "# Combine losses for multi-task learning\n",
        "task_a_weight = 0.5\n",
        "task_b_weight = 0.5\n",
        "combined_loss = task_a_loss * task_a_weight + task_b_loss * task_b_weight\n",
        "\n",
        "# Define layer wise learning rates\n",
        "bert_lr = 1e-6  # Learning rate for the BERT layer\n",
        "task_a_head_lr = 5e-3  # Learning rate for the Task A head\n",
        "task_b_head_lr = 5e-3  # Learning rate for the Task B head\n",
        "\n",
        "# Set up the optimizer with layer wise learning rates\n",
        "param_groups = [\n",
        "    {'params': model.bert.parameters(), 'lr': bert_lr},\n",
        "    {'params': model.task_a_head.parameters(), 'lr': task_a_head_lr},\n",
        "    {'params': model.task_b_head.parameters(), 'lr': task_b_head_lr}\n",
        "]\n",
        "optimizer = torch.optim.Adam(param_groups)\n",
        "\n",
        "# Optimize the combined loss\n",
        "optimizer.zero_grad()\n",
        "combined_loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "# Print the multi-task outputs\n",
        "print(\"Task A Output (Sentence Classification):\")\n",
        "print(task_a_output)\n",
        "print(\"\\nTask B Output (Named Entity Recognition):\")\n",
        "print(task_b_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18bIqmPJ8uTK",
        "outputId": "23d425bc-0d9b-4670-ef7e-024009ab715c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task A Output (Sentence Classification):\n",
            "tensor([[-0.4516, -0.2711, -0.2930,  0.3932, -0.0454],\n",
            "        [-0.6471, -0.1410, -0.3102,  0.4350,  0.0737],\n",
            "        [-0.5945, -0.1222, -0.1726,  0.5016,  0.0890],\n",
            "        [-0.6618, -0.0939, -0.2193,  0.4403,  0.1122]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Task B Output (Named Entity Recognition):\n",
            "tensor([[[-2.5900e-01,  3.4105e-02, -2.9591e-01,  6.7089e-01, -1.4280e-01,\n",
            "           1.2864e-01, -7.3645e-02, -7.1139e-01,  3.2045e-02,  1.7620e-01],\n",
            "         [-3.0260e-01, -2.5108e-01,  2.5255e-01,  4.9917e-01, -3.4996e-01,\n",
            "          -2.6063e-01, -6.3774e-02, -2.8200e-01, -1.0602e-01,  5.2566e-02],\n",
            "         [ 1.4944e-01, -4.6727e-01, -1.1942e-01,  7.0476e-01,  1.3117e-02,\n",
            "           8.2875e-02, -1.5034e-01, -5.0137e-01, -2.0650e-01,  1.2337e-01],\n",
            "         [ 2.6011e-01, -5.7434e-01, -6.8963e-02,  4.9465e-01,  2.2418e-01,\n",
            "           2.4502e-01,  8.7059e-02, -5.2728e-01,  2.2943e-02,  8.3204e-02],\n",
            "         [ 4.6886e-01, -4.5517e-01, -9.3392e-02,  2.1924e-01,  3.2991e-01,\n",
            "           2.0234e-01,  3.3873e-02, -4.3010e-01,  7.6502e-02, -5.1059e-02],\n",
            "         [-5.5652e-02, -2.5066e-01,  2.9182e-01,  1.3652e-01,  3.7135e-01,\n",
            "          -2.5493e-01, -1.7681e-01, -3.7111e-01, -3.0538e-01,  6.1820e-03],\n",
            "         [ 1.6859e-01, -2.6430e-01, -1.2165e-02,  6.6797e-02, -1.8798e-01,\n",
            "          -7.9820e-02, -3.3143e-01,  4.9764e-01,  1.1830e-01, -1.9942e-01],\n",
            "         [ 1.9636e-01, -1.9065e-01,  1.0841e-01, -2.2991e-02, -1.7052e-01,\n",
            "          -3.9578e-02, -1.2063e-01,  5.2054e-01,  2.1681e-02, -3.0174e-01],\n",
            "         [-1.2518e-01, -4.2755e-01,  4.5701e-02,  1.3056e-01, -1.0492e-01,\n",
            "          -2.4062e-01,  3.1163e-02, -3.5167e-01,  2.5897e-02,  1.5157e-01],\n",
            "         [ 2.7842e-03, -4.2534e-01,  6.5227e-02,  3.5931e-01, -1.3926e-02,\n",
            "          -3.0274e-01,  1.7670e-01, -3.7390e-01,  1.3714e-01,  2.6582e-01],\n",
            "         [-1.2126e-01, -4.1252e-01,  2.3395e-02,  1.6545e-01, -1.0427e-01,\n",
            "          -2.7559e-01,  5.3372e-02, -3.7486e-01,  3.6673e-02,  1.7586e-01]],\n",
            "\n",
            "        [[-4.4984e-02, -2.5786e-01, -1.7502e-01,  5.1913e-01, -3.9383e-01,\n",
            "          -1.7260e-01, -2.8977e-01, -8.4645e-01,  2.5688e-02,  1.6398e-01],\n",
            "         [-3.9212e-02, -6.6647e-01,  1.8903e-01,  4.1228e-01, -3.4300e-01,\n",
            "          -3.7882e-01, -3.2497e-01, -7.3446e-01, -1.2185e-01, -7.0879e-02],\n",
            "         [-1.1095e-01, -6.9250e-01,  4.6344e-01,  3.6110e-01,  1.0418e-01,\n",
            "          -3.3506e-01, -2.4724e-03, -2.9900e-01, -3.0452e-01, -1.1308e-01],\n",
            "         [-1.9685e-01, -7.4470e-01,  7.8380e-02,  4.9721e-01, -1.5749e-02,\n",
            "          -2.8163e-01, -2.0119e-01, -8.6452e-01, -6.0754e-01,  3.0275e-01],\n",
            "         [-4.3807e-02, -6.8024e-01, -2.8380e-01,  5.4256e-01, -2.1352e-01,\n",
            "          -3.8396e-02, -9.3914e-02, -7.2080e-01, -5.4117e-01,  7.2843e-02],\n",
            "         [ 1.6955e-01, -8.2764e-01, -1.3314e-03,  3.6520e-01, -9.1437e-02,\n",
            "           1.0894e-02,  1.3877e-01, -7.3688e-01, -2.1620e-01,  2.0847e-01],\n",
            "         [ 1.5344e-01, -9.6542e-01,  2.2697e-01, -8.0796e-02, -9.1574e-02,\n",
            "          -2.7664e-01, -3.4923e-02, -7.4269e-01,  3.0023e-03,  1.1938e-01],\n",
            "         [ 1.4999e-01, -5.0489e-01,  8.6687e-02,  5.3090e-01, -3.6444e-01,\n",
            "          -6.1247e-01, -8.1175e-02, -6.7563e-01,  9.7740e-02,  4.2146e-01],\n",
            "         [ 1.5811e-01, -2.4696e-01, -1.1234e-01,  1.7106e-01, -4.6599e-01,\n",
            "          -7.4574e-02,  8.2991e-03,  7.9220e-02,  8.6836e-02, -8.1664e-03],\n",
            "         [-6.3482e-02, -5.2367e-01,  8.7025e-02,  1.9343e-01, -1.9583e-01,\n",
            "          -2.9482e-01, -4.5671e-02, -6.3481e-01, -1.9631e-01,  1.5690e-01],\n",
            "         [ 1.2403e-01, -5.4228e-01,  1.4162e-01,  4.7024e-01, -3.5412e-01,\n",
            "          -5.8189e-01,  1.7039e-02, -6.8223e-01, -5.5147e-02,  3.4101e-01]],\n",
            "\n",
            "        [[-2.8450e-01, -1.2716e-01, -5.9104e-01,  4.7759e-01, -1.0838e-01,\n",
            "           1.1777e-01, -1.3895e-01, -6.3854e-01, -2.7270e-03,  1.2905e-01],\n",
            "         [ 7.2659e-02, -3.4354e-01, -1.0488e-01,  2.0401e-01, -2.2858e-01,\n",
            "           5.4900e-02, -5.9318e-01, -2.1060e-01, -1.4186e-01,  7.3671e-01],\n",
            "         [ 2.9586e-03, -6.2864e-01, -7.1530e-02,  1.0688e-02,  3.2816e-01,\n",
            "          -4.5382e-01, -1.4759e-01, -5.4295e-01, -2.2924e-01,  2.1300e-01],\n",
            "         [ 7.5619e-02, -2.3989e-01, -1.2642e-01,  2.2879e-01,  1.5119e-01,\n",
            "          -6.2906e-02, -3.0423e-01, -3.5230e-01, -1.2647e-01,  3.3650e-01],\n",
            "         [-1.5909e-01, -7.1205e-01,  2.9148e-01, -4.3956e-02,  2.5588e-01,\n",
            "          -2.6696e-01, -7.0963e-02, -6.9305e-01, -4.6461e-01,  3.5947e-01],\n",
            "         [ 3.0430e-03, -6.4551e-01, -3.7359e-01,  4.7927e-01,  1.5528e-01,\n",
            "           1.6187e-01, -2.1681e-01, -4.8372e-01, -1.4508e-01,  1.2399e-01],\n",
            "         [-1.8930e-01, -6.7311e-01, -6.7739e-02,  3.4695e-01, -5.8319e-02,\n",
            "          -2.5100e-01, -1.6104e-02, -5.0222e-01, -6.5300e-01,  4.2248e-01],\n",
            "         [-8.0312e-02, -5.8930e-01, -2.9176e-01,  3.3858e-01,  4.5509e-01,\n",
            "          -1.3878e-02, -3.6202e-01, -5.6373e-01,  7.1802e-02,  1.0222e-01],\n",
            "         [-2.2648e-01, -7.5317e-01,  9.6879e-02, -1.5448e-02,  1.9053e-01,\n",
            "          -2.2531e-01,  1.5114e-01, -5.6781e-01, -2.2231e-01,  7.9474e-02],\n",
            "         [ 1.1242e-01, -3.5772e-01,  6.1650e-04,  4.6714e-02, -1.0808e-01,\n",
            "          -4.9204e-03, -4.0163e-01,  5.0259e-01,  4.0767e-02, -2.1613e-01],\n",
            "         [ 1.0368e-01, -2.9609e-01,  3.8695e-02, -1.7686e-02, -7.4630e-02,\n",
            "           5.5347e-02, -3.0711e-01,  5.4266e-01, -1.0280e-02, -2.8811e-01]],\n",
            "\n",
            "        [[-2.8801e-01, -2.9462e-02, -3.7209e-01,  5.1935e-01, -1.6021e-01,\n",
            "           8.1917e-02, -2.3539e-01, -6.8838e-01,  1.2505e-01,  6.2079e-02],\n",
            "         [ 1.2823e-01, -2.0259e-01,  2.9102e-01,  2.3726e-01,  1.0719e-01,\n",
            "          -1.5138e-01,  1.5116e-01, -3.7834e-01, -7.3777e-02,  2.0433e-01],\n",
            "         [ 7.3173e-03, -2.0444e-01,  2.9966e-01,  1.5446e-01,  3.7408e-01,\n",
            "          -2.1947e-01, -5.5136e-01, -9.1770e-01, -2.3759e-01,  3.3024e-02],\n",
            "         [ 2.2524e-01, -2.6964e-01, -2.0381e-01,  6.7082e-01, -1.3980e-01,\n",
            "           2.5667e-02, -1.0061e-01, -5.6978e-01, -1.3718e-01,  6.6253e-02],\n",
            "         [ 4.3432e-03, -4.5609e-01,  7.8105e-02,  4.3313e-01,  1.2846e-01,\n",
            "           2.0977e-01,  2.7776e-01, -4.9394e-01, -5.6222e-05,  2.2250e-01],\n",
            "         [-4.8868e-02, -7.9733e-02,  4.2641e-01, -4.1024e-02, -1.6236e-01,\n",
            "          -2.9792e-01,  7.0175e-02, -4.8445e-01,  1.5485e-01, -1.5565e-01],\n",
            "         [ 6.8220e-02, -2.6223e-01,  2.5959e-01,  5.1823e-01, -1.4428e-01,\n",
            "          -6.3208e-01, -1.6970e-01, -3.1695e-01,  3.0254e-01,  3.7618e-01],\n",
            "         [ 2.4936e-02, -7.6031e-02, -8.3791e-02, -6.8150e-02, -8.5537e-02,\n",
            "           1.2185e-01, -3.3172e-01,  6.2485e-01, -3.0524e-02, -3.2483e-01],\n",
            "         [ 1.0657e-01, -2.8505e-01,  8.5767e-02,  1.4153e-01, -1.3392e-01,\n",
            "          -2.8180e-01,  1.0315e-01, -5.3167e-01,  9.0534e-03,  1.6010e-01],\n",
            "         [ 9.9805e-02, -2.6652e-01,  1.0692e-02,  2.6599e-01, -1.8390e-01,\n",
            "          -4.1771e-01,  6.9069e-02, -5.4986e-01,  1.3146e-01,  1.3662e-01],\n",
            "         [ 1.1804e-01, -2.9451e-01,  3.4705e-02,  2.0154e-01, -1.7254e-01,\n",
            "          -3.2874e-01,  8.1118e-02, -5.1154e-01,  6.3563e-02,  1.5010e-01]]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the given code, we set different learning rates for the BERT layers and the task-specific heads (Task A and Task B heads). The BERT layers have a lower learning rate (bert_lr = 1e-6) because they are pre-trained on a massive corpus and have already learned rich language representations. A lower learning rate helps preserve this valuable knowledge while allowing for fine-tuning.\n",
        "\n",
        "On the other hand, the task-specific heads have a higher learning rate (task_a_head_lr = task_b_head_lr = 5e-3) as they are randomly initialized and need to learn task-specific representations from scratch, requiring faster adaptation.\n",
        "\n",
        "Using layer-wise learning rates can lead to faster convergence by allowing layers that need more learning to have higher rates. It can also improve generalization by preserving pre-trained knowledge in lower layers and stability by preventing large updates to well-initialized layers.\n",
        "\n",
        "In the multi-task setting, layer-wise rates are particularly beneficial as they allow task-specific heads to quickly adapt to individual tasks while keeping the shared BERT layers relatively stable, enabling effective learning across multiple tasks simultaneously."
      ],
      "metadata": {
        "id": "Kpgqj3DKBwzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For Task 3 and Task 4, besides the technical explanation, also provide a brief write-up summarizing your key decisions and insights.**"
      ],
      "metadata": {
        "id": "ZHd74Xb2CR_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Task 3, the key decision is to strike a balance between leveraging the pre-trained knowledge from the BERT model and allowing the model to adapt to the specific tasks. Freezing the entire network limits the model's ability to learn, while freezing only the transformer backbone (BERT) and fine-tuning the task-specific heads allows the model to leverage the pre-trained knowledge while adapting to the task nuances. Freezing one task head can be useful if one task is more important or requires more fine-tuning, but may lead to suboptimal performance for that task. For transfer learning, choosing a pre-trained model like BERT and freezing the lower layers while fine-tuning the higher layers is a common approach, as it preserves the general language representations while allowing the model to specialize for the target task.\n",
        "\n",
        "For Task 4, implementing layer-wise learning rates can lead to faster convergence, better generalization, and improved stability by assigning higher rates to layers that need more learning and lower rates to well-initialized or pre-trained layers. In the multi-task setting, this approach is particularly beneficial as it allows the task-specific heads to quickly adapt to individual tasks while keeping the shared BERT layers relatively stable, enabling effective learning across multiple tasks simultaneously."
      ],
      "metadata": {
        "id": "7lw1DQ_hCTEQ"
      }
    }
  ]
}